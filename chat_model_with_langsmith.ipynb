{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4qZOXDPsusj/4PdzLLfZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalDevX/Agentic-AI-Journey/blob/main/chat_model_with_langsmith.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tutorial\n",
        "Langgraph <br>\n",
        "[https://langchain-ai.github.io/langgraph/tutorials/](https://langchain-ai.github.io/langgraph/tutorials/)"
      ],
      "metadata": {
        "id": "J0MnRMDTNubZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents\n",
        "A Long-Term Memory Agent\n",
        "[https://python.langchain.com/docs/versions/migrating_memory/long_term_memory_agent/](https://python.langchain.com/docs/versions/migrating_memory/long_term_memory_agent/)"
      ],
      "metadata": {
        "id": "0u_IR7OSMmRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#References\n",
        "Memory Saver Updates <br> [https://python.langchain.com/docs/versions/migrating_memory/](https://python.langchain.com/docs/versions/migrating_memory/)\n",
        "\n",
        "langchain_core messages <br>\n",
        "[https://python.langchain.com/api_reference/core/messages.html](https://python.langchain.com/api_reference/core/messages.html)\n",
        "\n",
        "langchain_core prompt <br>\n",
        "[https://python.langchain.com/api_reference/core/prompts.html](https://python.langchain.com/api_reference/core/prompts.html)"
      ],
      "metadata": {
        "id": "S47BT14jFJgB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0L2oy4H28-s"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core langgraph>0.2.27"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[groq]\""
      ],
      "metadata": {
        "id": "G5-vD1d08Z_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n"
      ],
      "metadata": {
        "id": "cuqe-1_o8fnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "LANGSMITH_API_KEY = os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
        "LANGSMITH_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IrYYU9Ic8mPq",
        "outputId": "831a642d-e5c1-4b23-a826-6ee9cb9371b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")"
      ],
      "metadata": {
        "id": "2UlqDg8w_MD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
      ],
      "metadata": {
        "id": "UfTHNZE48i-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "norUaUThACVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmLl0n_yEEz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_model(state: MessagesState):\n",
        "    prompt = prompt_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": response}"
      ],
      "metadata": {
        "id": "wSK7Q-jeA4aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a compassionate mental health chatbot. Respond with empathy.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "lIPGQ9AiAk3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LangGraph Workflow\n",
        "# workflow = StateGraph(state_schema=State)\n",
        "\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "workflow.add_node(\"model\", call_model)\n",
        "workflow.add_edge(START, \"model\")\n",
        "app_chatbot = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "zDsy8qwgCKps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
        "query = \"Hi! I'm bilal.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app_chatbot.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxVsyv-bB7Yz",
        "outputId": "e24523b5-3f6b-432a-b2d2-c60083f3ed0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Bilal! It's wonderful to meet you! I'm here to listen and support you in any way I can. How are you feeling today? Is there anything on your mind that you'd like to talk about or share? I'm here to listen without judgment and offer support.\n"
          ]
        }
      ]
    }
  ]
}